# ALFALIBRAS

Sistema de AlfabetizaÃ§Ã£o em Libras (TCC)

Bem-vindo ao repositÃ³rio do Sistema de Visao Computacional para AlfabetizaÃ§Ã£o em Libras como ferramenta auxiliadora para docentes. Este projeto utiliza VisÃ£o Computacional (OpenCV/MediaPipe) e InteligÃªncia Artificial (PyTorch) para traduzir sinais da LÃ­ngua Brasileira de Sinais (Libras) em tempo real, com uma interface grÃ¡fica amigÃ¡vel desenvolvida em Flet.

## Funcionalidades

- TraduÃ§Ã£o em Tempo Real: Captura gestos via webcam e traduz para texto/Ã¡udio.

- Aprendizado ContÃ­nuo: Permite gravar novos sinais e retreinar a IA automaticamente.

- Interface Responsiva: AplicaÃ§Ã£o desktop moderna e adaptÃ¡vel.

- Feedback Visual: Barra de confianÃ§a da IA e histÃ³rico de detecÃ§Ãµes.

## Tecnologias Utilizadas

- Linguagem: Python 3.11+

- VisÃ£o Computacional: OpenCV, CVZone, MediaPipe

- InteligÃªncia Artificial: PyTorch (Rede Neural MLP)

- Interface GrÃ¡fica: Flet (Flutter para Python)

- Processamento de Dados: NumPy, Pandas

## ConstruÃ§Ã£o (Build)

Clone o repositÃ³rio:
~~~bash
git clone https://github.com/TechnoDark-ti/alfalibras.git
~~~
~~~bash
cd alfalibras
~~~

Crie e ative um ambiente virtual (Recomendado):

### Linux/Mac
~~~python
virtualenv -p /usr/bin/python3.11 PROJETO-LIBRAS/
~~~
~~~bash
source venv/bin/activate
~~~
### Windows
~~~bash
python -m venv venv
~~~ 
~~~bash
venv\Scripts\activate
~~~

Instale as dependÃªncias:
~~~python
pip3 install -r requirements.txt
~~~

(Se nÃ£o tiver o arquivo requirements.txt, instale pelo resources/install_libs.sh)

Nota para usuÃ¡rios Linux: Ã‰ necessÃ¡rio instalar bibliotecas de sistema para o Flet/OpenCV. Consulte resources/install_libs


### ðŸ³ Executando com Docker

Este projeto estÃ¡ containerizado para facilitar a execuÃ§Ã£o em qualquer ambiente, garantindo que todas as dependÃªncias (Python, PyTorch, OpenCV, Mediapipe) sejam configuradas automaticamente.

#### PrÃ©-requisitos
* [Docker](https://docs.docker.com/get-docker/) instalado.
* Webcam conectada (necessÃ¡ria para a traduÃ§Ã£o em tempo real).

#### OpÃ§Ã£o 1: Baixar imagem pronta do Docker Hub
Se vocÃª deseja apenas executar a aplicaÃ§Ã£o:
~~~bash
docker pull technodark/libras-tcc:lasted
~~~
~~~bash
docker run -p 8443:8443 --device=/dev/video0:/dev/video0 technodark/libras-tcc:lasted
~~~

#### OpÃ§Ã£o 2: Construir a imagem localmente
Se vocÃª alterou o cÃ³digo e deseja testar localmente:

Construa a imagem:

~~~Bash

docker build -t libras-tcc .
~~~
Execute o container:

~~~Bash
docker run -p 8443:8443 --device=/dev/video0:/dev/video0 libras-tcc
~~~

Nota importante: > * A flag --device=/dev/video0:/dev/video0 Ã© obrigatÃ³ria para que o container tenha permissÃ£o de acessar a sua webcam.

ApÃ³s rodar, acesse no seu navegador: http://localhost:8443


### Como Executar

Para iniciar o sistema principal:
~~~zsh
python3 src/main.py
~~~

## Como Treinar Novos Sinais

O sistema possui um modo de aprendizado integrado:

Abra o aplicativo.

No campo "RÃ³tulo", digite o nome do sinal (ex: "A", "Obrigado").

FaÃ§a o gesto na frente da cÃ¢mera.

Clique em GRAVAR repetidamente (recomenda-se ~100 amostras por sinal, variando levemente a posiÃ§Ã£o).

O sistema irÃ¡ salvar os dados, retreinar o modelo automaticamente e recarregar a IA.

Teste o novo sinal imediatamente!

Se preferir treinar manualmente via terminal:
~~~bash
python3 src/train_model.py
~~~

## Estrutura do Projeto

- src/core: MÃ³dulos de lÃ³gica (CÃ¢mera, Classificador, Buffer).

- src/ui: Interface grÃ¡fica e componentes Flet.

- src/models: Onde o modelo treinado (libras_model.pt) Ã© salvo.

- data/raw_samples: Amostras de gestos coletadas (arquivos .csv).

- resources: Scripts de build e assets.

~~~bash
.
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ ui
â”‚   â”‚   â”œâ”€â”€ components.py
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ tests
â”‚   â”‚   â”œâ”€â”€ test_tracker.py
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_model.py
â”‚   â”‚   â”œâ”€â”€ test_camera_.py
â”‚   â”‚   â”œâ”€â”€ test_buffer.py
â”‚   â”œâ”€â”€ testes.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â””â”€â”€ libras_model.pt
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ core
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”œâ”€â”€ translator.py
â”‚   â”‚   â”œâ”€â”€ signal_classifier.py
â”‚   â”‚   â”œâ”€â”€ signal_buffer.py
â”‚   â”‚   â”œâ”€â”€ hand_tracker.py
â”‚   â”‚   â””â”€â”€ camera.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ share
â”œâ”€â”€ resources
â”‚   â”œâ”€â”€ resources
â”‚   â”‚   â”‚       â””â”€â”€ bin
â”‚   â”‚   â”‚       â”œâ”€â”€ TradutorLibras.desktop
â”‚   â”‚   â””â”€â”€ assets
â”‚   â”œâ”€â”€ PROJETO-LIBRAS.pod
â”‚   â”œâ”€â”€ install_toolchain.sh
â”‚   â”œâ”€â”€ install_libs.sh
â”‚   â”œâ”€â”€ generate_assets.py
â”‚   â”œâ”€â”€ docs_projeto
â”‚   â”‚   â”œâ”€â”€ libs necessÃ¡rias para o projeto.md
â”‚   â”‚   â””â”€â”€ Bem-vindo.md
â”‚   â”œâ”€â”€ appimagetool
â”‚   â””â”€â”€ appimage.sh
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ data
â””â”€â”€ bin
~~~


## Autoria

Desenvolvido por MÃ¡rcio Moda como parte do Trabalho de ConclusÃ£o de Curso
Todos os direitos reservado ao Autor
Este projeto Ã© restritamente proibido de venda sem a prÃ©via autorizaÃ§Ã£o.
Contatos: marciomoda18@gmail.com | marciomoda65@gmail.com

# LICENÃ‡A
MIT License

Copyright (c) 2025 MÃ¡rcio Moda

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, not and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so.
